import streamlit as st
import pandas as pd
import requests
import time
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from src.scanner.threat_intel import ThreatCorrelator
from src.dashboard.ui_styles import glass_card

from src.utils.report_generator import ReportGenerator
from src.dashboard.components.stats_dashboard import render_stats_dashboard
from src.dashboard.components.batch_scanner import render_batch_scanner
from src.dashboard.components.threat_timeline import render_threat_timeline
from src.dashboard.components.file_comparator import render_file_comparator
from src.dashboard.components.threat_hunter import render_threat_hunter
from src.dashboard.components.alert_manager import render_alert_manager
from src.dashboard.components.api_integration import render_api_integration
from src.dashboard.components.scan_scheduler import render_scan_scheduler
from src.dashboard.components.risk_calculator import render_risk_calculator
from src.dashboard.components.audit_log import render_audit_log
from src.dashboard.components.performance_metrics import render_performance_metrics
from src.dashboard.components.reputation_db import render_reputation_db

import os

API_URL = os.getenv("BACKEND_API_URL", "http://localhost:80")
correlator = ThreatCorrelator()
report_gen = ReportGenerator()

def run():
    # 1. User-Centric Hero Section
    st.markdown("""
        <div style="text-align: center; padding: 3rem 0; margin-bottom: 2rem;">
            <h1 class="hero-title">
                Secure Your Digital World
            </h1>
            <p style="font-size: 1.2rem; color: #94A3B8; max-width: 600px; margin: 0 auto; line-height: 1.6;">
                Advanced AI-powered threat detection at your fingertips. <br>
                Upload your files instantly to scan for malware, ransomware, and zero-day threats.
            </p>
        </div>
    """, unsafe_allow_html=True)

    # Real-time Pulse Terminal


    st.markdown("<div style='margin-top: 3rem;'></div>", unsafe_allow_html=True)
    
    # Tabbed Interface for Different Modes
    st.markdown("""
        <div style="display: flex; align-items: center; margin-bottom: 2rem;">
            <div style="width: 5px; height: 35px; background: linear-gradient(#00F5FF, #0072FF); margin-right: 20px; border-radius: 3px; box-shadow: 0 0 15px #00F5FF;"></div>
            <h2 style="margin: 0; font-weight: 800; font-size: 1.8rem; letter-spacing: 2px; color: #FFFFFF;">ADVANCED THREAT ANALYSIS CENTER</h2>
        </div>
    """, unsafe_allow_html=True)
    
    # Create tabs for different functionalities - EXPANDED TO 7 TABS
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "üîç Single Scan",
        "üöÄ Batch Scanner",
        "üìä Statistics",
        "‚è±Ô∏è Timeline",
        "üîÑ File Compare",
        "üéØ Threat Hunter",
        "‚öôÔ∏è Advanced Tools"
    ])
    
    # TAB 1: Single File Scan (Original functionality)
    with tab1:
        st.markdown("""
            <div style="text-align: center; margin-bottom: 1.5rem;">
                <h3 style="color: #00F5FF; font-weight: 800; font-size: 1.5rem;">NEURAL QUARANTINE CHAMBER</h3>
                <p style="color: #FFFFFF; font-weight: 700;">Ultra-Deep Single File Analysis</p>
            </div>
        """, unsafe_allow_html=True)
        
        uploaded_file = st.file_uploader("Drop Asset for Ultra-Deep Neural Inspection", 
                                         type=["pdf", "exe", "jpg", "png", "doc", "docx", "mp4", "zip", "txt", "bin"])

        if uploaded_file:
            if st.button("‚ö° EXECUTE ELITE INTELLIGENCE SCAN", use_container_width=True):
                with st.status("Initializing Elite Intelligence Pipeline...", expanded=True) as status:
                    st.write("üì° Synchronizing with Global SOC Nodes...")
                    time.sleep(0.4)
                    st.write("üß¨ Activating 3-Layer Neural Ensemble...")
                    time.sleep(0.3)
                    st.write("üî¨ Deploying Heuristic Fragmentation Analyzer...")
                    time.sleep(0.3)

                    try:
                        files = {"file": (uploaded_file.name, uploaded_file.getvalue(), uploaded_file.type)}
                        response = requests.post(f"{API_URL}/malware/scan", files=files, data={"filename": uploaded_file.name}, timeout=30)

                        if response.status_code == 200:
                            result = response.json()
                            
                            # Threat correlation
                            variant_info = correlator.find_similar_threats(
                                result.get('sha256', ''), 
                                result.get('risk_score', 0)
                            )

                            status.update(label="‚úÖ SCAN COMPLETE - INTELLIGENCE READY", state="complete", expanded=False)

                            # Store in session state for report generation
                            st.session_state['last_scan_result'] = result
                            st.session_state['last_scan_filename'] = uploaded_file.name

                            # Display Results
                            st.markdown("<div style='margin-top: 2rem;'></div>", unsafe_allow_html=True)
                            
                            is_malicious = result.get('is_malicious', False)
                            risk_score = result.get('risk_score', 0)
                            
                            # Animation Wrapper
                            st.markdown('<div class="animate-slide-up">', unsafe_allow_html=True)
                            
                            # Verdict Banner
                            if is_malicious:
                                st.markdown(f"""
                                <div style="padding: 2rem; background: linear-gradient(135deg, rgba(255,0,60,0.2), rgba(139,0,0,0.2)); 
                                     border: 2px solid #FF003C; border-radius: 12px; text-align: center; 
                                     box-shadow: 0 0 40px rgba(255,0,60,0.4); margin-bottom: 2rem;">
                                    <h1 style="color: #FF003C; font-weight: 900; font-size: 3rem; margin: 0; 
                                         text-shadow: 0 0 20px rgba(255,0,60,0.8);">üö® THREAT DETECTED</h1>
                                    <p style="color: #FFFFFF; font-size: 1.3rem; font-weight: 800; margin-top: 1rem;">
                                        RISK SCORE: {risk_score}/100 | CLASSIFICATION: MALICIOUS
                                    </p>
                                </div>
                                """, unsafe_allow_html=True)
                            else:
                                st.markdown(f"""
                                <div style="padding: 2rem; background: linear-gradient(135deg, rgba(0,255,136,0.2), rgba(0,100,60,0.2)); 
                                     border: 2px solid #00FF88; border-radius: 12px; text-align: center; 
                                     box-shadow: 0 0 40px rgba(0,255,136,0.4); margin-bottom: 2rem;">
                                    <h1 style="color: #00FF88; font-weight: 900; font-size: 3rem; margin: 0; 
                                         text-shadow: 0 0 20px rgba(0,255,136,0.8);">‚úÖ FILE CLEAN</h1>
                                    <p style="color: #FFFFFF; font-size: 1.3rem; font-weight: 800; margin-top: 1rem;">
                                        RISK SCORE: {risk_score}/100 | CLASSIFICATION: SAFE
                                    </p>
                                </div>
                                """, unsafe_allow_html=True)

                            # Report Generation
                            from src.dashboard.components.report_template import generate_report_html
                            report_html = generate_report_html(
                                file_name=uploaded_file.name,
                                file_hash=result.get('sha256', 'N/A'),
                                risk_score=risk_score,
                                file_size=f"{uploaded_file.size / 1024:.2f} KB",
                                threat_level="CRITICAL" if is_malicious else "SAFE"
                            )
                            
                            c1, c2, c3 = st.columns([1,2,1])
                            with c2:
                                st.download_button(
                                    label="üìÑ DOWNLOAD OFFICIAL CERTIFICATE",
                                    data=report_html,
                                    file_name=f"SmartGuard_Report_{uploaded_file.name}.html",
                                    mime="text/html",
                                    use_container_width=True
                                )
                            
                            # Animation End
                            st.markdown('</div>', unsafe_allow_html=True)

                            # Variant Detection Alert
                            if variant_info:
                                st.markdown(f"""
                                <div style="padding: 1.5rem; background: rgba(255,165,0,0.15); border-left: 5px solid #FFA500; 
                                     border-radius: 8px; margin-bottom: 2rem;">
                                    <h3 style="color: #FFA500; font-weight: 800; margin: 0;">‚ö†Ô∏è VARIANT CORRELATION DETECTED</h3>
                                    <p style="color: #FFFFFF; font-weight: 700; margin-top: 0.8rem;">{variant_info}</p>
                                </div>
                                """, unsafe_allow_html=True)

                            # Detailed Analysis
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.markdown("""
                                <h3 style="color: #00F5FF; font-weight: 800; margin-bottom: 1rem;">üî¨ LAYER BREAKDOWN</h3>
                                """, unsafe_allow_html=True)
                                
                                layers = result.get('layer_results', {})
                                for layer_name, layer_data in layers.items():
                                    score = layer_data.get('score', 0)
                                    color = '#FF003C' if score > 70 else '#FFA500' if score > 40 else '#00FF88'
                                    st.markdown(f"""
                                    <div class="glass-card">
                                        <div style="display: flex; justify-content: space-between; align-items: center;">
                                            <span style="color: #FFFFFF; font-weight: 700; font-size: 1rem;">{layer_name}</span>
                                            <span style="color: {color}; font-weight: 900; font-size: 1.4rem;">{score}</span>
                                        </div>
                                    </div>
                                    """, unsafe_allow_html=True)

                            with col2:
                                st.markdown("""
                                <h3 style="color: #00F5FF; font-weight: 800; margin-bottom: 1rem;">üìã FILE METADATA</h3>
                                """, unsafe_allow_html=True)
                                
                                metadata = result.get('metadata', {})
                                st.markdown(f"""
                                <div class="glass-card">
                                    <p style="color: #FFFFFF; font-weight: 700; margin: 0.5rem 0;">
                                        <strong style="color: #00F5FF;">SHA256:</strong> {result.get('sha256', 'N/A')[:32]}...
                                    </p>
                                    <p style="color: #FFFFFF; font-weight: 700; margin: 0.5rem 0;">
                                        <strong style="color: #00F5FF;">Size:</strong> {metadata.get('size', 0)} bytes
                                    </p>
                                    <p style="color: #FFFFFF; font-weight: 700; margin: 0.5rem 0;">
                                        <strong style="color: #00F5FF;">Type:</strong> {metadata.get('type', 'Unknown')}
                                    </p>
                                    <p style="color: #FFFFFF; font-weight: 700; margin: 0.5rem 0;">
                                        <strong style="color: #00F5FF;">Entropy:</strong> {metadata.get('entropy', 0):.2f}
                                    </p>
                                </div>
                                """, unsafe_allow_html=True)

                            # Threat Indicators
                            if is_malicious and result.get('threats'):
                                st.markdown("""
                                <h3 style="color: #FF003C; font-weight: 800; margin-top: 2rem; margin-bottom: 1rem;">
                                    üö® DETECTED THREAT INDICATORS
                                </h3>
                                """, unsafe_allow_html=True)
                                
                                for threat in result['threats'][:10]:
                                    st.markdown(f"""
                                    <div style="padding: 0.8rem; border-left: 4px solid #FF003C; 
                                         background: rgba(255,0,60,0.1); margin-bottom: 0.5rem; border-radius: 4px;">
                                        <p style="color: #FFFFFF; font-weight: 700; margin: 0;">‚ö†Ô∏è {threat}</p>
                                    </div>
                                    """, unsafe_allow_html=True)

                            # Report Download Section
                            st.markdown("<div style='margin-top: 2rem;'></div>", unsafe_allow_html=True)
                            st.markdown("""
                            <h3 style="color: #00F5FF; font-weight: 800; text-align: center; margin-bottom: 1rem;">
                                üì• EXPORT INTELLIGENCE REPORT
                            </h3>
                            """, unsafe_allow_html=True)
                            
                            col1, col2, col3 = st.columns(3)
                            
                            with col1:
                                json_report = report_gen.generate_json_report(result, uploaded_file.name)
                                st.download_button(
                                    label="üìÑ JSON Report",
                                    data=json_report,
                                    file_name=f"report_{uploaded_file.name}.json",
                                    mime="application/json",
                                    use_container_width=True
                                )
                            
                            with col2:
                                txt_report = report_gen.generate_text_report(result, uploaded_file.name)
                                st.download_button(
                                    label="üìù Text Report",
                                    data=txt_report,
                                    file_name=f"report_{uploaded_file.name}.txt",
                                    mime="text/plain",
                                    use_container_width=True
                                )
                                
                            with col3:
                                pdf_data = report_gen.generate_pdf_report(result, uploaded_file.name)
                                st.download_button(
                                    label="üìï PDF Report",
                                    data=pdf_data,
                                    file_name=f"report_{uploaded_file.name}.pdf",
                                    mime="application/pdf",
                                    use_container_width=True
                                )

                            # Explainable AI Breakdown
                            if result.get('risk_breakdown'):
                                st.markdown("""
                                <h3 style="color: #00F5FF; font-weight: 800; margin-top: 2rem; margin-bottom: 1rem;">
                                    üß† EXPLAINABLE AI INSIGHTS
                                </h3>
                                """, unsafe_allow_html=True)
                                
                                for insight in result['risk_breakdown']:
                                    st.markdown(f"""
                                    <div style="padding: 1rem; background: rgba(0, 245, 255, 0.05); border-left: 4px solid #00F5FF; margin-bottom: 0.8rem; border-radius: 4px;">
                                        <p style="color: #FFFFFF; font-weight: 600; margin: 0;">üí° {insight}</p>
                                    </div>
                                    """, unsafe_allow_html=True)
                            
                            st.markdown("<div style='margin-top: 2rem;'></div>", unsafe_allow_html=True)
                            if st.button("üîç View Raw Analysis Data", use_container_width=True):
                                st.session_state['show_raw_json'] = not st.session_state.get('show_raw_json', False)
                            
                            if st.session_state.get('show_raw_json', False):
                                st.json(result)

                        else:
                            status.update(label=f"‚ùå SCAN FAILED - HTTP {response.status_code}", state="error")
                            st.error(f"Backend returned error: {response.status_code}\n\n{response.text}")

                    except requests.exceptions.RequestException as e:
                        status.update(label="‚ùå INTELLIGENCE ENGINE OFFLINE", state="error")
                        st.error(f"Cannot connect to backend API: {str(e)}")

        # Cybersecurity Knowledge Base
        with st.expander("üìö CYBERSECURITY KNOWLEDGE BASE (WIKI)", expanded=False):
            st.markdown("""
            <div style="color: #FFFFFF; font-weight: 700;">
                <h4 style="color: #00F5FF;">üî¨ Entropy Fragmentation Analysis</h4>
                <p>Advanced heuristic that detects non-uniform entropy distribution across file chunks. 
                Identifies hidden/obfuscated payloads by analyzing variance in randomness patterns.</p>
                
                <h4 style="color: #00F5FF;">üß¨ Hybrid Ensemble Architecture</h4>
                <p>3-layer scanning engine combining Signature-based, ML-based, and Heuristic analysis 
                with weighted risk aggregation for maximum detection accuracy.</p>
                
                <h4 style="color: #00F5FF;">üéØ Heuristic Signals</h4>
                <p>Behavioral indicators extracted from file structure, entropy, and metadata patterns 
                that suggest malicious intent without relying on known signatures.</p>
                
                <h4 style="color: #00F5FF;">üîó Threat Correlation</h4>
                <p>Intelligent system that identifies malware variants by comparing SHA256 hashes and 
                structural similarities (entropy, risk score) with historical threat database.</p>
            </div>
            """, unsafe_allow_html=True)

    # TAB 2: Batch Scanner
    with tab2:
        render_batch_scanner(API_URL)

    # TAB 3: Statistics Dashboard
    with tab3:
        try:
            history_response = requests.get(f"{API_URL}/malware/history")
            if history_response.status_code == 200:
                scan_history = history_response.json()
                render_stats_dashboard(scan_history)
            else:
                st.warning("Unable to load scan history for statistics.")
        except:
            st.error("Cannot connect to backend to retrieve statistics.")

    # TAB 4: Threat Timeline
    with tab4:
        try:
            history_response = requests.get(f"{API_URL}/malware/history")
            if history_response.status_code == 200:
                scan_history = history_response.json()
                render_threat_timeline(scan_history)
            else:
                st.warning("Unable to load scan history for timeline.")
        except:
            st.error("Cannot connect to backend to retrieve timeline data.")
    
    # TAB 5: File Comparison Mode (NEW)
    with tab5:
        render_file_comparator(API_URL)
    
    # TAB 6: Threat Hunter (NEW)
    with tab6:
        render_threat_hunter(API_URL)
    
    # TAB 7: Advanced Tools (NEW)
    with tab7:
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <h2 style="color: #00F5FF; font-weight: 900; font-size: 2rem; text-shadow: 0 0 15px rgba(0, 245, 255, 0.5);">
                ‚öôÔ∏è ADVANCED TOOLS & CONFIGURATION
            </h2>
            <p style="color: #FFFFFF; font-weight: 700; font-size: 1rem;">Professional-Grade Security Features</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Sub-tabs for advanced tools
        adv_tab1, adv_tab2, adv_tab3, adv_tab4, adv_tab5, adv_tab6, adv_tab7 = st.tabs([
            "üö® Alerts", 
            "üîå API", 
            "‚è∞ Scheduler", 
            "üßÆ Risk Calc", 
            "üìù Audit", 
            "‚ö° Metrics", 
            "üóÑÔ∏è Reputation"
        ])
        
        with adv_tab1: render_alert_manager()
        with adv_tab2: render_api_integration()
        with adv_tab3: render_scan_scheduler()
        with adv_tab4: render_risk_calculator()
        with adv_tab5: render_audit_log()
        with adv_tab6: render_performance_metrics()
        with adv_tab7: render_reputation_db()

    # Historical Intelligence Archive (Below tabs)
    st.markdown("<div style='margin-top: 4rem;'></div>", unsafe_allow_html=True)
    st.markdown("""
        <div style="display: flex; align-items: center; margin-bottom: 2rem;">
            <div style="width: 5px; height: 35px; background: linear-gradient(#00F5FF, #0072FF); margin-right: 20px; border-radius: 3px; box-shadow: 0 0 15px #00F5FF;"></div>
            <h2 style="margin: 0; font-weight: 800; font-size: 1.8rem; letter-spacing: 2px; color: #FFFFFF;">HISTORICAL INTELLIGENCE ARCHIVE</h2>
        </div>
    """, unsafe_allow_html=True)

    @st.cache_data(ttl=60, show_spinner=False)
    def fetch_scan_history():
        try:
            return requests.get(f"{API_URL}/malware/history", timeout=2).json()
        except:
            return []

    try:
        history = fetch_scan_history()
        
        if history:
            # Advanced Filtering
            col1, col2, col3 = st.columns(3)
            
            with col1:
                search_term = st.text_input("üîç Search (Filename/Hash)", "")
            
            with col2:
                detection_filter = st.selectbox(
                    "Detection Status",
                    ["All", "Malicious Only", "Clean Only"]
                )
            
            with col3:
                severity_filter = st.selectbox(
                    "Risk Severity",
                    ["All", "Critical (90+)", "High (70-89)", "Medium (40-69)", "Low (0-39)"]
                )
            
            # Apply filters
            filtered_history = history
            
            if search_term:
                filtered_history = [
                    h for h in filtered_history 
                    if search_term.lower() in h.get('filename', '').lower() 
                    or search_term.lower() in h.get('sha256', '').lower()
                ]
            
            if detection_filter == "Malicious Only":
                filtered_history = [h for h in filtered_history if h.get('is_malicious', False)]
            elif detection_filter == "Clean Only":
                filtered_history = [h for h in filtered_history if not h.get('is_malicious', False)]
            
            if severity_filter != "All":
                if severity_filter == "Critical (90+)":
                    filtered_history = [h for h in filtered_history if h.get('risk_score', 0) >= 90]
                elif severity_filter == "High (70-89)":
                    filtered_history = [h for h in filtered_history if 70 <= h.get('risk_score', 0) < 90]
                elif severity_filter == "Medium (40-69)":
                    filtered_history = [h for h in filtered_history if 40 <= h.get('risk_score', 0) < 70]
                elif severity_filter == "Low (0-39)":
                    filtered_history = [h for h in filtered_history if h.get('risk_score', 0) < 40]
            
            if filtered_history:
                # Normalize data to prevent KeyErrors on legacy records
                normalized = []
                for h in filtered_history:
                    h_norm = h.copy()
                    h_norm['timestamp'] = h.get('timestamp', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
                    h_norm['is_malicious'] = h.get('is_malicious', h.get('detection') == 'MALICIOUS')
                    normalized.append(h_norm)
                
                df = pd.DataFrame(normalized)
                
                # Ensure columns exist
                cols_to_show = ['filename', 'sha256', 'risk_score', 'is_malicious', 'timestamp']
                available_cols = [c for c in cols_to_show if c in df.columns]
                
                st.dataframe(
                    df[available_cols],
                    use_container_width=True,
                    height=400
                )
            else:
                st.info("No records match your filter criteria.")
        else:
            st.info("No scan history available yet. Upload files to begin building your intelligence archive.")
    except Exception as e:
        # Silently fail if backend is offline to keep UI smooth
        st.warning("History unavailable (Backend Offline)")

